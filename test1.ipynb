{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4d6ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using neuron select type: first-last\n",
      "Synch representation size action: 528\n",
      "Synch representation size out: 528\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 212\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Backward pass and optimization step\u001b[39;00m\n\u001b[32m    211\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gradient_clipping != -\u001b[32m1\u001b[39m:\n\u001b[32m    214\u001b[39m     nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clipping)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ctm/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ctm/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ctm/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from models.ctm import ContinuousThoughtMachine\n",
    "from utils.losses import image_classification_loss\n",
    "\n",
    "# Hyperparameters (as defined in train_distributed.py)\n",
    "d_model = 512\n",
    "dropout = 0.0\n",
    "backbone_type = 'resnet18-4'\n",
    "d_input = 128\n",
    "heads = 4\n",
    "iterations = 50  # internal ticks for CTM\n",
    "positional_embedding_type = 'none'\n",
    "synapse_depth = 4\n",
    "n_synch_out = 32\n",
    "n_synch_action = 32\n",
    "neuron_select_type = 'first-last'\n",
    "n_random_pairing_self = 256\n",
    "memory_length = 25\n",
    "deep_memory = True\n",
    "memory_hidden_dims = 4\n",
    "dropout_nlm = None  # if None, use same dropout as rest of model\n",
    "do_normalisation = False  # apply layernorm in NLMs\n",
    "batch_size = 32\n",
    "batch_size_test = 32\n",
    "lr = 1e-3\n",
    "training_iterations = 100001\n",
    "warmup_steps = 5000\n",
    "use_scheduler = True\n",
    "scheduler_type = 'cosine'  # 'cosine' or 'multistep'\n",
    "milestones = [8000, 15000, 20000]  # for multistep scheduler\n",
    "gamma = 0.1\n",
    "weight_decay = 0.0\n",
    "gradient_clipping = -1\n",
    "num_workers_train = 0\n",
    "seed = 412\n",
    "track_every = 1000\n",
    "n_test_batches = 20  # evaluate on this many batches for metrics (-1 for full eval)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data loading (CIFAR-10) with standard normalization and augmentation for training\n",
    "dataset_mean = [0.4914, 0.4822, 0.4465]\n",
    "dataset_std = [0.2470, 0.2435, 0.2616]\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(dataset_mean, dataset_std),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(dataset_mean, dataset_std),\n",
    "])\n",
    "train_data = datasets.CIFAR10(root='data/', train=True, download=True, transform=train_transform)\n",
    "test_data = datasets.CIFAR10(root='data/', train=False, download=True, transform=test_transform)\n",
    "class_labels = train_data.classes\n",
    "out_dims = len(class_labels)  # number of classes, should be 10 for CIFAR-10\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, \n",
    "                                           num_workers=num_workers_train, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=False, num_workers=0)\n",
    "# Separate loader for evaluating training metrics (no shuffle for consistency)\n",
    "train_eval_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_test, shuffle=False, num_workers=0)\n",
    "\n",
    "# Model initialization\n",
    "model = ContinuousThoughtMachine(\n",
    "    iterations=iterations,\n",
    "    d_model=d_model,\n",
    "    d_input=d_input,\n",
    "    heads=heads,\n",
    "    n_synch_out=n_synch_out,\n",
    "    n_synch_action=n_synch_action,\n",
    "    synapse_depth=synapse_depth,\n",
    "    memory_length=memory_length,\n",
    "    deep_nlms=deep_memory,\n",
    "    memory_hidden_dims=memory_hidden_dims,\n",
    "    do_layernorm_nlm=do_normalisation,\n",
    "    backbone_type=backbone_type,\n",
    "    positional_embedding_type=positional_embedding_type,\n",
    "    out_dims=out_dims,\n",
    "    prediction_reshaper=[-1],  # task-specific reshaping ([-1] for image classification)\n",
    "    dropout=dropout,\n",
    "    dropout_nlm=dropout_nlm,\n",
    "    neuron_select_type=neuron_select_type,\n",
    "    n_random_pairing_self=n_random_pairing_self\n",
    ").to(device)\n",
    "\n",
    "# Optimizer (AdamW) and initial learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, eps=1e-8)\n",
    "\n",
    "# Lists for tracking metrics\n",
    "iteration_points = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Evaluation function for training & test datasets (uses at most n_test_batches batches)\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_train_loss = 0.0\n",
    "    total_train_correct = 0.0\n",
    "    total_train_samples = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_eval_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(inputs)\n",
    "            if isinstance(outputs, tuple):\n",
    "                # CTM/LSTM outputs: predictions, certainties, (maybe other)\n",
    "                predictions, certainties, _ = outputs\n",
    "                loss_val, where_most_certain = image_classification_loss(predictions, certainties, targets, use_most_certain=True)\n",
    "                preds = predictions.argmax(dim=1)  # shape [batch, iterations]\n",
    "                idx = torch.arange(predictions.size(0), device=device)\n",
    "                preds = preds[idx, where_most_certain]  # pick class at most certain step for each sample\n",
    "            else:\n",
    "                # FF baseline output\n",
    "                predictions = outputs\n",
    "                loss_val = nn.CrossEntropyLoss()(predictions, targets)\n",
    "                preds = predictions.argmax(dim=1)\n",
    "        total_train_loss += loss_val.item() * inputs.size(0)\n",
    "        total_train_correct += (preds == targets).sum().item()\n",
    "        total_train_samples += inputs.size(0)\n",
    "        if n_test_batches != -1 and batch_idx >= n_test_batches - 1:\n",
    "            break\n",
    "    avg_train_loss = total_train_loss / total_train_samples if total_train_samples > 0 else 0.0\n",
    "    train_acc = total_train_correct / total_train_samples if total_train_samples > 0 else 0.0\n",
    "\n",
    "    total_test_loss = 0.0\n",
    "    total_test_correct = 0.0\n",
    "    total_test_samples = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(inputs)\n",
    "            if isinstance(outputs, tuple):\n",
    "                predictions, certainties, _ = outputs\n",
    "                loss_val, where_most_certain = image_classification_loss(predictions, certainties, targets, use_most_certain=True)\n",
    "                preds = predictions.argmax(dim=1)\n",
    "                idx = torch.arange(predictions.size(0), device=device)\n",
    "                preds = preds[idx, where_most_certain]\n",
    "            else:\n",
    "                predictions = outputs\n",
    "                loss_val = nn.CrossEntropyLoss()(predictions, targets)\n",
    "                preds = predictions.argmax(dim=1)\n",
    "        total_test_loss += loss_val.item() * inputs.size(0)\n",
    "        total_test_correct += (preds == targets).sum().item()\n",
    "        total_test_samples += inputs.size(0)\n",
    "        if n_test_batches != -1 and batch_idx >= n_test_batches - 1:\n",
    "            break\n",
    "    avg_test_loss = total_test_loss / total_test_samples if total_test_samples > 0 else 0.0\n",
    "    test_acc = total_test_correct / total_test_samples if total_test_samples > 0 else 0.0\n",
    "    model.train()\n",
    "    return avg_train_loss, train_acc, avg_test_loss, test_acc\n",
    "\n",
    "# Training loop (single device, no distributed training)\n",
    "model.train()\n",
    "train_iter = iter(train_loader)  # iterator for continuous sampling\n",
    "for it in range(training_iterations):\n",
    "    # Fetch the next training batch (restart if at end of epoch)\n",
    "    try:\n",
    "        inputs, targets = next(train_iter)\n",
    "    except StopIteration:\n",
    "        train_iter = iter(train_loader)\n",
    "        inputs, targets = next(train_iter)\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Adjust learning rate (warmup and scheduler)\n",
    "    if it < warmup_steps:\n",
    "        current_lr = lr * float(it + 1) / float(warmup_steps)\n",
    "    elif use_scheduler and scheduler_type == 'cosine':\n",
    "        # Cosine annealing schedule after warmup\n",
    "        progress = float(it - warmup_steps) / float(training_iterations - warmup_steps)\n",
    "        cos_factor = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        eta_min = 1e-7\n",
    "        current_lr = eta_min + cos_factor * (lr - eta_min)\n",
    "    elif use_scheduler and scheduler_type == 'multistep':\n",
    "        milestones_passed = sum(1 for m in milestones if it >= m)\n",
    "        current_lr = lr * (gamma ** milestones_passed)\n",
    "    else:\n",
    "        current_lr = lr\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = current_lr\n",
    "\n",
    "    # Forward pass and loss computation\n",
    "    outputs = model(inputs)\n",
    "    if isinstance(outputs, tuple):\n",
    "        predictions, certainties, _ = outputs\n",
    "        loss, where_most_certain = image_classification_loss(predictions, certainties, targets, use_most_certain=True)\n",
    "    else:\n",
    "        predictions = outputs\n",
    "        loss = nn.CrossEntropyLoss()(predictions, targets)\n",
    "\n",
    "    # Backward pass and optimization step\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if gradient_clipping != -1:\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clipping)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Periodic evaluation and logging\n",
    "    if it % track_every == 0 and it != 0:\n",
    "        avg_train_loss, train_acc, avg_test_loss, test_acc = evaluate()\n",
    "        iteration_points.append(it)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        print(f\"Iteration {it}: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "              f\"Test Loss={avg_test_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
    "\n",
    "# Final evaluation at the end of training (if not already done on last iteration)\n",
    "if iteration_points and iteration_points[-1] != training_iterations - 1:\n",
    "    avg_train_loss, train_acc, avg_test_loss, test_acc = evaluate()\n",
    "    iteration_points.append(training_iterations - 1)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(f\"Final Iteration: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.4f}, \"\n",
    "          f\"Test Loss={avg_test_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
    "\n",
    "# Plot training and test accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(iteration_points, train_losses, label='Train Loss')\n",
    "plt.plot(iteration_points, test_losses, label='Test Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Test Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(iteration_points, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(iteration_points, test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Test Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6262e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model state\n",
    "torch.save(model.state_dict(), './logs/ctm_cifar10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59a857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
